{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3934c0e3-2da2-40de-b2f4-464334d009e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gymnasium in c:\\users\\admin\\anaconda3\\envs\\env\\lib\\site-packages (0.28.1)\n",
      "Requirement already satisfied: pygame in c:\\users\\admin\\anaconda3\\envs\\env\\lib\\site-packages (2.6.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\admin\\anaconda3\\envs\\env\\lib\\site-packages (1.21.6)\n",
      "Requirement already satisfied: jax-jumpy>=1.0.0 in c:\\users\\admin\\anaconda3\\envs\\env\\lib\\site-packages (from gymnasium) (1.0.0)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in c:\\users\\admin\\anaconda3\\envs\\env\\lib\\site-packages (from gymnasium) (0.0.4)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in c:\\users\\admin\\anaconda3\\envs\\env\\lib\\site-packages (from gymnasium) (2.0.0)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in c:\\users\\admin\\anaconda3\\envs\\env\\lib\\site-packages (from gymnasium) (4.4.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.8.0 in c:\\users\\admin\\anaconda3\\envs\\env\\lib\\site-packages (from gymnasium) (6.7.0)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\admin\\anaconda3\\envs\\env\\lib\\site-packages (from importlib-metadata>=4.8.0->gymnasium) (3.11.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade gymnasium pygame numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1cb15dfb-ef50-4a07-9b1b-f404bba2aee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6ea9972-4b22-413c-b7bd-4ac6905b07df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-0.01344995, -0.01388491, -0.01334325, -0.01792721], dtype=float32),\n",
       " {})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env=gym.make(\"CartPole-v1\",render_mode=\"human\")\n",
    "env.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3eab842",
   "metadata": {},
   "source": [
    "# Partie 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e8266f",
   "metadata": {},
   "source": [
    "Exercice 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57a58a10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Espace d'actions :Discrete(2)\n",
      "Espace d'observations:Box([-4.8000002e+00 -3.4028235e+38 -4.1887903e-01 -3.4028235e+38], [4.8000002e+00 3.4028235e+38 4.1887903e-01 3.4028235e+38], (4,), float32)\n",
      "Action :1  ,Observations:[-0.02995311  0.17524716  0.00082595 -0.28852364]  ,Reward:1.0\n",
      "Action :1  ,Observations:[-0.02644817  0.37035733 -0.00494452 -0.58094597]  ,Reward:1.0\n",
      "Action :1  ,Observations:[-0.01904102  0.5655482  -0.01656344 -0.8751824 ]  ,Reward:1.0\n",
      "Action :0  ,Observations:[-0.00773006  0.3706553  -0.03406709 -0.5877526 ]  ,Reward:1.0\n",
      "Action :0  ,Observations:[-0.00031695  0.17602658 -0.04582214 -0.30599266]  ,Reward:1.0\n",
      "Action :0  ,Observations:[ 0.00320358 -0.01841347 -0.05194199 -0.02810573]  ,Reward:1.0\n",
      "Action :1  ,Observations:[ 0.00283531  0.1774134  -0.05250411 -0.33671397]  ,Reward:1.0\n",
      "Action :0  ,Observations:[ 0.00638358 -0.01692358 -0.05923839 -0.06103929]  ,Reward:1.0\n",
      "Action :0  ,Observations:[ 0.00604511 -0.21114835 -0.06045917  0.21238095]  ,Reward:1.0\n",
      "Action :0  ,Observations:[ 0.00182214 -0.40535614 -0.05621155  0.48539618]  ,Reward:1.0\n",
      "Action :1  ,Observations:[-0.00628498 -0.20948787 -0.04650363  0.17554033]  ,Reward:1.0\n",
      "Action :0  ,Observations:[-0.01047474 -0.4039145  -0.04299283  0.45319784]  ,Reward:1.0\n",
      "Action :0  ,Observations:[-0.01855303 -0.598403   -0.03392887  0.73202497]  ,Reward:1.0\n",
      "Action :1  ,Observations:[-0.03052109 -0.402829   -0.01928837  0.42885968]  ,Reward:1.0\n",
      "Action :1  ,Observations:[-0.03857767 -0.20743927 -0.01071118  0.13015917]  ,Reward:1.0\n",
      "Action :0  ,Observations:[-0.04272645 -0.40240616 -0.00810799  0.4194437 ]  ,Reward:1.0\n",
      "Action :0  ,Observations:[-5.0774578e-02 -5.9741229e-01  2.8088212e-04  7.0955956e-01]  ,Reward:1.0\n",
      "Action :0  ,Observations:[-0.06272282 -0.7925381   0.01447207  1.0023309 ]  ,Reward:1.0\n",
      "Action :0  ,Observations:[-0.07857358 -0.9878504   0.03451869  1.2995234 ]  ,Reward:1.0\n",
      "Action :1  ,Observations:[-0.09833059 -0.7931832   0.06050916  1.0178429 ]  ,Reward:1.0\n",
      "Action :0  ,Observations:[-0.11419426 -0.9890573   0.08086602  1.3288952 ]  ,Reward:1.0\n",
      "Action :0  ,Observations:[-0.1339754  -1.1851012   0.10744392  1.6457487 ]  ,Reward:1.0\n",
      "Action :0  ,Observations:[-0.15767743 -1.3813038   0.1403589   1.9698832 ]  ,Reward:1.0\n",
      "Action :1  ,Observations:[-0.18530351 -1.1879157   0.17975657  1.7237841 ]  ,Reward:1.0\n",
      "Action :1  ,Observations:[-0.20906182 -0.9952489   0.21423224  1.4920048 ]  ,Reward:1.0\n",
      "Action :0  ,Observations:[ 0.04426998 -0.15640178  0.0411327   0.28394917]  ,Reward:1.0\n",
      "Action :1  ,Observations:[0.04114195 0.03811009 0.04681168 0.00451774]  ,Reward:1.0\n",
      "Action :0  ,Observations:[ 0.04190415 -0.15765086  0.04690203  0.3115951 ]  ,Reward:1.0\n",
      "Action :0  ,Observations:[ 0.03875113 -0.35340855  0.05313394  0.6186929 ]  ,Reward:1.0\n",
      "Action :0  ,Observations:[ 0.03168296 -0.5492308   0.06550779  0.9276258 ]  ,Reward:1.0\n",
      "Action :1  ,Observations:[ 0.02069834 -0.3550516   0.08406031  0.6562272 ]  ,Reward:1.0\n",
      "Action :1  ,Observations:[ 0.01359731 -0.16119425  0.09718485  0.39115256]  ,Reward:1.0\n",
      "Action :1  ,Observations:[0.01037343 0.03242379 0.1050079  0.13062334]  ,Reward:1.0\n",
      "Action :1  ,Observations:[ 0.0110219   0.22589703  0.10762037 -0.12717237]  ,Reward:1.0\n",
      "Action :1  ,Observations:[ 0.01553984  0.41932586  0.10507692 -0.3840576 ]  ,Reward:1.0\n",
      "Action :1  ,Observations:[ 0.02392636  0.61281127  0.09739577 -0.64184916]  ,Reward:1.0\n",
      "Action :0  ,Observations:[ 0.03618259  0.41647625  0.08455879 -0.32015327]  ,Reward:1.0\n",
      "Action :1  ,Observations:[ 0.04451211  0.6102986   0.07815573 -0.58501726]  ,Reward:1.0\n",
      "Action :1  ,Observations:[ 0.05671808  0.80424374  0.06645538 -0.8520926 ]  ,Reward:1.0\n",
      "Action :0  ,Observations:[ 0.07280296  0.60828185  0.04941352 -0.53927505]  ,Reward:1.0\n",
      "Action :1  ,Observations:[ 0.0849686   0.8026756   0.03862802 -0.8159881 ]  ,Reward:1.0\n",
      "Action :0  ,Observations:[ 0.10102211  0.6070466   0.02230826 -0.51140976]  ,Reward:1.0\n",
      "Action :1  ,Observations:[ 0.11316304  0.80184734  0.01208007 -0.7969801 ]  ,Reward:1.0\n",
      "Action :1  ,Observations:[ 0.12919998  0.9968015  -0.00385953 -1.0858384 ]  ,Reward:1.0\n",
      "Action :1  ,Observations:[ 0.14913602  1.1919742  -0.0255763  -1.37973   ]  ,Reward:1.0\n",
      "Action :1  ,Observations:[ 0.1729755  1.3874059 -0.0531709 -1.6803004]  ,Reward:1.0\n",
      "Action :0  ,Observations:[ 0.20072362  1.1929388  -0.08677691 -1.4046369 ]  ,Reward:1.0\n",
      "Action :0  ,Observations:[ 0.22458239  0.99899495 -0.11486965 -1.1402961 ]  ,Reward:1.0\n",
      "Action :1  ,Observations:[ 0.24456228  1.1954156  -0.13767557 -1.4666828 ]  ,Reward:1.0\n",
      "Action :1  ,Observations:[ 0.26847062  1.3919283  -0.16700922 -1.7990116 ]  ,Reward:1.0\n",
      "Action :1  ,Observations:[ 0.29630917  1.5884788  -0.20298946 -2.138608  ]  ,Reward:1.0\n",
      "Action :0  ,Observations:[ 0.32807875  1.395862   -0.24576162 -1.9148848 ]  ,Reward:1.0\n",
      "Action :1  ,Observations:[-0.01947087  0.24282132 -0.02490532 -0.26602602]  ,Reward:1.0\n",
      "Action :1  ,Observations:[-0.01461444  0.4382897  -0.03022584 -0.5664591 ]  ,Reward:1.0\n",
      "Action :1  ,Observations:[-0.00584865  0.6338224  -0.04155502 -0.8685091 ]  ,Reward:1.0\n",
      "Action :0  ,Observations:[ 0.0068278   0.43928966 -0.05892521 -0.5891757 ]  ,Reward:1.0\n",
      "Action :0  ,Observations:[ 0.01561359  0.2450402  -0.07070872 -0.31562117]  ,Reward:1.0\n",
      "Action :0  ,Observations:[ 0.0205144   0.05099293 -0.07702114 -0.04604864]  ,Reward:1.0\n",
      "Action :1  ,Observations:[ 0.02153425  0.24712999 -0.07794212 -0.36200383]  ,Reward:1.0\n",
      "Action :1  ,Observations:[ 0.02647685  0.44326827 -0.0851822  -0.67820984]  ,Reward:1.0\n",
      "Action :1  ,Observations:[ 0.03534222  0.63946384 -0.09874639 -0.9964495 ]  ,Reward:1.0\n",
      "Action :0  ,Observations:[ 0.0481315   0.44579113 -0.11867538 -0.73633987]  ,Reward:1.0\n",
      "Action :0  ,Observations:[ 0.05704732  0.25249085 -0.13340218 -0.48323756]  ,Reward:1.0\n",
      "Action :0  ,Observations:[ 0.06209713  0.059479   -0.14306693 -0.23539616]  ,Reward:1.0\n",
      "Action :1  ,Observations:[ 0.06328671  0.25632435 -0.14777485 -0.5695659 ]  ,Reward:1.0\n",
      "Action :0  ,Observations:[ 0.0684132   0.06355017 -0.15916617 -0.32684398]  ,Reward:1.0\n",
      "Action :1  ,Observations:[ 0.06968421  0.26053783 -0.16570304 -0.6651881 ]  ,Reward:1.0\n",
      "Action :1  ,Observations:[ 0.07489496  0.45752957 -0.17900681 -1.0051223 ]  ,Reward:1.0\n",
      "Action :0  ,Observations:[ 0.08404555  0.26519105 -0.19910926 -0.77357197]  ,Reward:1.0\n",
      "Action :1  ,Observations:[ 0.08934937  0.46241358 -0.2145807  -1.1217132 ]  ,Reward:1.0\n",
      "Action :0  ,Observations:[-0.03748955 -0.15367603 -0.00571621  0.2793888 ]  ,Reward:1.0\n",
      "Action :0  ,Observations:[-4.0563069e-02 -3.4871596e-01 -1.2843637e-04  5.7026333e-01]  ,Reward:1.0\n",
      "Action :1  ,Observations:[-0.04753739 -0.15359221  0.01127683  0.27753997]  ,Reward:1.0\n",
      "Action :1  ,Observations:[-0.05060923  0.04136705  0.01682763 -0.01156503]  ,Reward:1.0\n",
      "Action :0  ,Observations:[-0.04978189 -0.15399213  0.01659633  0.28637934]  ,Reward:1.0\n",
      "Action :0  ,Observations:[-0.05286174 -0.3493468   0.02232392  0.5842501 ]  ,Reward:1.0\n",
      "Action :0  ,Observations:[-0.05984867 -0.54477423  0.03400892  0.8838809 ]  ,Reward:1.0\n",
      "Action :0  ,Observations:[-0.07074416 -0.74034107  0.05168654  1.1870582 ]  ,Reward:1.0\n",
      "Action :0  ,Observations:[-0.08555098 -0.93609375  0.0754277   1.4954841 ]  ,Reward:1.0\n",
      "Action :0  ,Observations:[-0.10427285 -1.1320475   0.10533738  1.8107338 ]  ,Reward:1.0\n",
      "Action :1  ,Observations:[-0.1269138  -0.93824553  0.14155206  1.5525541 ]  ,Reward:1.0\n",
      "Action :1  ,Observations:[-0.14567871 -0.7450762   0.17260315  1.3071756 ]  ,Reward:1.0\n",
      "Action :0  ,Observations:[-0.16058023 -0.9419135   0.19874665  1.6485381 ]  ,Reward:1.0\n",
      "Action :1  ,Observations:[-0.1794185  -0.7495925   0.23171741  1.423783  ]  ,Reward:1.0\n",
      "Action :0  ,Observations:[ 0.02696525 -0.15832756  0.02438544  0.32546303]  ,Reward:1.0\n",
      "Action :0  ,Observations:[ 0.02379869 -0.35378808  0.0308947   0.6257352 ]  ,Reward:1.0\n",
      "Action :1  ,Observations:[ 0.01672293 -0.15911072  0.0434094   0.34294012]  ,Reward:1.0\n",
      "Action :0  ,Observations:[ 0.01354072 -0.3548225   0.05026821  0.6489896 ]  ,Reward:1.0\n",
      "Action :1  ,Observations:[ 0.00644427 -0.16043551  0.063248    0.37255007]  ,Reward:1.0\n",
      "Action :1  ,Observations:[0.00323556 0.03373359 0.070699   0.1004613 ]  ,Reward:1.0\n",
      "Action :1  ,Observations:[ 0.00391023  0.22777483  0.07270823 -0.16910526]  ,Reward:1.0\n",
      "Action :1  ,Observations:[ 0.00846573  0.42178482  0.06932612 -0.43799397]  ,Reward:1.0\n",
      "Action :0  ,Observations:[ 0.01690142  0.2257536   0.06056624 -0.12428793]  ,Reward:1.0\n",
      "Action :1  ,Observations:[ 0.02141649  0.41995794  0.05808048 -0.3972647 ]  ,Reward:1.0\n",
      "Action :0  ,Observations:[ 0.02981565  0.22406213  0.05013519 -0.0868504 ]  ,Reward:1.0\n",
      "Action :0  ,Observations:[0.0342969  0.02825871 0.04839818 0.22121924]  ,Reward:1.0\n",
      "Action :0  ,Observations:[ 0.03486207 -0.16752042  0.05282256  0.5287676 ]  ,Reward:1.0\n",
      "Action :1  ,Observations:[0.03151166 0.02682015 0.06339791 0.25318593]  ,Reward:1.0\n",
      "Action :1  ,Observations:[ 0.03204807  0.22098225  0.06846163 -0.01884562]  ,Reward:1.0\n",
      "Action :0  ,Observations:[0.03646771 0.02494868 0.06808472 0.2946279 ]  ,Reward:1.0\n"
     ]
    }
   ],
   "source": [
    "print(f\"Espace d'actions :{env.action_space}\")\n",
    "print(f\"Espace d'observations:{env.observation_space}\")\n",
    "\n",
    "for _ in range(100):\n",
    "    action=env.action_space.sample()\n",
    "    observation,reward,done,_,_=env.step(action)\n",
    "    print(f\"Action :{action}  ,Observations:{observation}  ,Reward:{reward}\")\n",
    "\n",
    "    if done:\n",
    "        env.reset()\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d7a9aa",
   "metadata": {},
   "source": [
    "#### Exercice 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92c863c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Essai 1\n",
      "Action choisie : 1\n",
      "Nouvelle observation : [-0.02313193  0.19961339 -0.00219802 -0.31304553]\n",
      "Récompense obtenue : 1.0\n",
      "Épisode terminé ? False\n",
      "--------------------------------------------------\n",
      "Essai 2\n",
      "Action choisie : 1\n",
      "Nouvelle observation : [-0.01913966  0.3947666  -0.00845893 -0.6064208 ]\n",
      "Récompense obtenue : 1.0\n",
      "Épisode terminé ? False\n",
      "--------------------------------------------------\n",
      "Essai 3\n",
      "Action choisie : 1\n",
      "Nouvelle observation : [-0.01124433  0.5900058  -0.02058735 -0.90175605]\n",
      "Récompense obtenue : 1.0\n",
      "Épisode terminé ? False\n",
      "--------------------------------------------------\n",
      "Essai 4\n",
      "Action choisie : 0\n",
      "Nouvelle observation : [ 5.5578811e-04  3.9516872e-01 -3.8622472e-02 -6.1561465e-01]\n",
      "Récompense obtenue : 1.0\n",
      "Épisode terminé ? False\n",
      "--------------------------------------------------\n",
      "Essai 5\n",
      "Action choisie : 0\n",
      "Nouvelle observation : [ 0.00845916  0.20060706 -0.05093476 -0.33534196]\n",
      "Récompense obtenue : 1.0\n",
      "Épisode terminé ? False\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "\n",
    "env = gym.make(\"CartPole-v1\", render_mode=\"human\")\n",
    "observation, _ = env.reset()\n",
    "\n",
    "for i in range(5):  # Essayer 5 actions différentes\n",
    "    action = env.action_space.sample()  # Action aléatoire\n",
    "    observation, reward, done, _, _ = env.step(action)\n",
    "\n",
    "    print(f\"Essai {i+1}\")\n",
    "    print(f\"Action choisie : {action}\")\n",
    "    print(f\"Nouvelle observation : {observation}\")\n",
    "    print(f\"Récompense obtenue : {reward}\")\n",
    "    print(f\"Épisode terminé ? {done}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "    if done:\n",
    "        env.reset()\n",
    "\n",
    "env.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0687e0a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observation : [-0.03105721 -0.22379124 -0.0365691   0.29018632], Récompense : 1.0\n"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "\n",
    "env = gym.make(\"CartPole-v1\", render_mode=\"human\")\n",
    "observation, _ = env.reset()\n",
    "\n",
    "episode_length = 0  # Compteur de durée\n",
    "\n",
    "while True:\n",
    "    action = input(\"Entrez une action (0 = Gauche, 1 = Droite, Q = Quitter) : \")\n",
    "\n",
    "    if action.lower() == 'q':\n",
    "        break  # Quitter l'application\n",
    "\n",
    "    try:\n",
    "        action = int(action)\n",
    "        if action not in [0, 1]:\n",
    "            raise ValueError(\"Action invalide\")\n",
    "    except ValueError:\n",
    "        print(\" Veuillez entrer 0 ou 1\")\n",
    "        continue\n",
    "\n",
    "    # Appliquer l'action\n",
    "    observation, reward, done, _, _ = env.step(action)\n",
    "\n",
    "    # Afficher les nouvelles valeurs\n",
    "    print(f\"Observation : {observation}, Récompense : {reward}\")\n",
    "\n",
    "    episode_length += 1\n",
    "\n",
    "    if done:\n",
    "        print(f\" Épisode terminé après {episode_length} actions.\")\n",
    "        observation, _ = env.reset()\n",
    "        episode_length = 0  # Réinitialiser le compteur\n",
    "\n",
    "env.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c9f594e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Épisode 1 terminé en 12 étapes.\n",
      "Épisode 2 terminé en 14 étapes.\n",
      "Épisode 3 terminé en 17 étapes.\n",
      "Épisode 4 terminé en 48 étapes.\n",
      "Épisode 5 terminé en 43 étapes.\n",
      "Épisode 6 terminé en 12 étapes.\n",
      "Épisode 7 terminé en 14 étapes.\n",
      "Épisode 8 terminé en 41 étapes.\n",
      "Épisode 9 terminé en 16 étapes.\n",
      "Épisode 10 terminé en 31 étapes.\n",
      " Durée moyenne sur 10 épisodes : 24.80 étapes\n"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "\n",
    "env = gym.make(\"CartPole-v1\")\n",
    "num_episodes = 10\n",
    "episode_durations = []\n",
    "\n",
    "for episode in range(num_episodes):\n",
    "    observation, _ = env.reset()\n",
    "    done = False\n",
    "    step_count = 0\n",
    "\n",
    "    while not done:\n",
    "        action = env.action_space.sample()  # Action aléatoire\n",
    "        observation, reward, done, truncated, _ = env.step(action)\n",
    "        step_count += 1\n",
    "\n",
    "    episode_durations.append(step_count)\n",
    "    print(f\"Épisode {episode+1} terminé en {step_count} étapes.\")\n",
    "\n",
    "# Calcul de la durée moyenne\n",
    "avg_duration = np.mean(episode_durations)\n",
    "print(f\" Durée moyenne sur {num_episodes} épisodes : {avg_duration:.2f} étapes\")\n",
    "\n",
    "env.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae6565d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
